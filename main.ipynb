{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T21:29:07.974342Z",
     "start_time": "2024-03-28T21:29:07.858237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puZgvM8r0aJx",
    "outputId": "ebdb2225-aa01-4a30-9994-e9c186c69751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:52:40.995550Z",
     "start_time": "2024-03-29T01:52:40.992696Z"
    },
    "id": "6Oi4Ha2-0aJy"
   },
   "outputs": [],
   "source": [
    "# Model from Hugging Face hub\n",
    "base_model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# New instruction dataset\n",
    "stack_overflow_dataset = \"Mxode/StackOverflow-QA-C-Language-40k\"\n",
    "# Fine-tuned model\n",
    "new_model = \"llama-2-7b-chat-stack-overflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(stack_overflow_dataset, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T01:52:56.810637Z",
     "start_time": "2024-03-29T01:52:55.907172Z"
    },
    "id": "-TEmF43d0aJy"
   },
   "outputs": [],
   "source": [
    "# dataset currently has 'question' and 'answer' columns. We need to combine them into a single column named 'text'\n",
    "dataset = dataset.map(\n",
    "    lambda examples: {\n",
    "        \"text\": \"<s>[INST]\" + examples[\"question\"] + \"[\\INST] \" + examples[\"answer\"] + \"</s>\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8739ffb31bd147e4b2dff66b9f6ae37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1549, 'grad_norm': 0.3336416184902191, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
      "{'loss': 2.4767, 'grad_norm': 1.453829288482666, 'learning_rate': 0.0002, 'epoch': 0.0}\n",
      "{'loss': 2.002, 'grad_norm': 0.42404285073280334, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
      "{'loss': 2.2998, 'grad_norm': 0.7494381666183472, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
      "{'loss': 1.9278, 'grad_norm': 0.4462108910083771, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
      "{'loss': 2.1755, 'grad_norm': 0.6799669861793518, 'learning_rate': 0.0002, 'epoch': 0.01}\n",
      "{'loss': 1.8452, 'grad_norm': 0.3923417031764984, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 2.1849, 'grad_norm': 0.6918219327926636, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 1.8184, 'grad_norm': 0.3401746451854706, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 2.1991, 'grad_norm': 0.8835895657539368, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 1.8687, 'grad_norm': 0.3712921142578125, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 2.1573, 'grad_norm': 0.9280964136123657, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 1.8653, 'grad_norm': 0.3519379198551178, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 2.2532, 'grad_norm': 0.7922613620758057, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 1.8616, 'grad_norm': 0.3534374237060547, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 2.213, 'grad_norm': 0.8143483400344849, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 1.9036, 'grad_norm': 0.3238692879676819, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 2.191, 'grad_norm': 0.7301739454269409, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 1.7551, 'grad_norm': 0.3680906295776367, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
      "{'loss': 2.1261, 'grad_norm': 0.6663084030151367, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
      "{'loss': 1.7671, 'grad_norm': 0.32431530952453613, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
      "{'loss': 2.1722, 'grad_norm': 0.6358453035354614, 'learning_rate': 0.0002, 'epoch': 0.05}\n",
      "{'loss': 1.7499, 'grad_norm': 0.30766743421554565, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
      "{'loss': 2.2304, 'grad_norm': 0.5920864939689636, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
      "{'loss': 1.8964, 'grad_norm': 0.3353179097175598, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
      "{'loss': 2.1624, 'grad_norm': 0.6592592597007751, 'learning_rate': 0.0002, 'epoch': 0.06}\n",
      "{'loss': 1.7866, 'grad_norm': 0.6793273687362671, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 2.0861, 'grad_norm': 0.8599699139595032, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 1.7698, 'grad_norm': 0.2906602919101715, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 2.1643, 'grad_norm': 0.6528099775314331, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 1.8185, 'grad_norm': 0.6255078315734863, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
      "{'loss': 2.083, 'grad_norm': 0.6412681937217712, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
      "{'loss': 1.8048, 'grad_norm': 0.4140450060367584, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
      "{'loss': 2.134, 'grad_norm': 0.6247105598449707, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
      "{'loss': 1.7036, 'grad_norm': 0.2886503338813782, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 2.1652, 'grad_norm': 0.62113356590271, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 1.8749, 'grad_norm': 0.32124876976013184, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 2.1712, 'grad_norm': 0.5389708280563354, 'learning_rate': 0.0002, 'epoch': 0.09}\n",
      "{'loss': 1.7616, 'grad_norm': 0.32456961274147034, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
      "{'loss': 2.0706, 'grad_norm': 0.615050733089447, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
      "{'loss': 1.7692, 'grad_norm': 0.3726755976676941, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
      "{'loss': 2.1637, 'grad_norm': 0.6330196261405945, 'learning_rate': 0.0002, 'epoch': 0.1}\n",
      "{'loss': 1.7693, 'grad_norm': 0.3253452181816101, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
      "{'loss': 2.1383, 'grad_norm': 0.5967913866043091, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
      "{'loss': 1.793, 'grad_norm': 0.272797554731369, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
      "{'loss': 2.1573, 'grad_norm': 0.7218561768531799, 'learning_rate': 0.0002, 'epoch': 0.11}\n",
      "{'loss': 1.7466, 'grad_norm': 0.33724361658096313, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 2.1549, 'grad_norm': 0.6099629402160645, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 1.7629, 'grad_norm': 0.2674576938152313, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 2.0836, 'grad_norm': 0.6750418543815613, 'learning_rate': 0.0002, 'epoch': 0.12}\n",
      "{'loss': 1.7812, 'grad_norm': 0.3019212484359741, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
      "{'loss': 2.1738, 'grad_norm': 0.704407811164856, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
      "{'loss': 1.8542, 'grad_norm': 0.33701056241989136, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
      "{'loss': 2.092, 'grad_norm': 0.7361205220222473, 'learning_rate': 0.0002, 'epoch': 0.13}\n",
      "{'loss': 1.784, 'grad_norm': 0.36384713649749756, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "{'loss': 2.1694, 'grad_norm': 0.499690443277359, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "{'loss': 1.8236, 'grad_norm': 0.41817259788513184, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "{'loss': 2.0924, 'grad_norm': 0.6353288888931274, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "{'loss': 1.815, 'grad_norm': 0.2794591784477234, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 2.1749, 'grad_norm': 0.644951581954956, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 1.7367, 'grad_norm': 0.308081716299057, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 2.0975, 'grad_norm': 0.554469108581543, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 1.7569, 'grad_norm': 0.39720433950424194, 'learning_rate': 0.0002, 'epoch': 0.15}\n",
      "{'loss': 2.0834, 'grad_norm': 0.5169650316238403, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
      "{'loss': 1.8076, 'grad_norm': 0.2946007251739502, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
      "{'loss': 2.1099, 'grad_norm': 0.5239307284355164, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
      "{'loss': 1.8052, 'grad_norm': 0.3317372500896454, 'learning_rate': 0.0002, 'epoch': 0.16}\n",
      "{'loss': 2.1635, 'grad_norm': 0.5337411761283875, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
      "{'loss': 1.8011, 'grad_norm': 0.34285855293273926, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
      "{'loss': 2.0599, 'grad_norm': 0.6817638278007507, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
      "{'loss': 1.736, 'grad_norm': 0.32000598311424255, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
      "{'loss': 2.1185, 'grad_norm': 0.6382238268852234, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
      "{'loss': 1.7015, 'grad_norm': 0.26959744095802307, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
      "{'loss': 2.0666, 'grad_norm': 0.4886416792869568, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
      "{'loss': 1.8392, 'grad_norm': 0.2988693416118622, 'learning_rate': 0.0002, 'epoch': 0.18}\n",
      "{'loss': 2.2095, 'grad_norm': 0.6432709693908691, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "{'loss': 1.7827, 'grad_norm': 0.328603059053421, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "{'loss': 2.1593, 'grad_norm': 0.6157119274139404, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "{'loss': 1.7764, 'grad_norm': 0.31386515498161316, 'learning_rate': 0.0002, 'epoch': 0.19}\n",
      "{'loss': 2.0733, 'grad_norm': 0.557245671749115, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
      "{'loss': 1.6669, 'grad_norm': 0.3144482374191284, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
      "{'loss': 2.0346, 'grad_norm': 0.5342994332313538, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
      "{'loss': 1.8139, 'grad_norm': 0.3684195876121521, 'learning_rate': 0.0002, 'epoch': 0.2}\n",
      "{'loss': 2.1459, 'grad_norm': 0.559022843837738, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
      "{'loss': 1.822, 'grad_norm': 0.3064701557159424, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
      "{'loss': 2.0437, 'grad_norm': 0.7737366557121277, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
      "{'loss': 1.7787, 'grad_norm': 0.31445780396461487, 'learning_rate': 0.0002, 'epoch': 0.21}\n",
      "{'loss': 2.1473, 'grad_norm': 0.5182000398635864, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 1.8237, 'grad_norm': 0.28157949447631836, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 2.1317, 'grad_norm': 0.6133400797843933, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 1.8306, 'grad_norm': 0.3063809871673584, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 2.1095, 'grad_norm': 0.5508823990821838, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
      "{'loss': 1.7731, 'grad_norm': 0.27595606446266174, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
      "{'loss': 1.9882, 'grad_norm': 0.5798371434211731, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
      "{'loss': 1.811, 'grad_norm': 0.3664722144603729, 'learning_rate': 0.0002, 'epoch': 0.23}\n",
      "{'loss': 2.0595, 'grad_norm': 0.4907360374927521, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
      "{'loss': 1.867, 'grad_norm': 0.29056668281555176, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
      "{'loss': 2.1939, 'grad_norm': 0.5886416435241699, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
      "{'loss': 1.7266, 'grad_norm': 0.32855454087257385, 'learning_rate': 0.0002, 'epoch': 0.24}\n",
      "{'loss': 2.0566, 'grad_norm': 0.8349544405937195, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
      "{'loss': 1.8108, 'grad_norm': 0.304673433303833, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
      "{'loss': 2.178, 'grad_norm': 0.705371081829071, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
      "{'loss': 1.7104, 'grad_norm': 0.366600900888443, 'learning_rate': 0.0002, 'epoch': 0.25}\n",
      "{'loss': 2.1655, 'grad_norm': 0.6131206154823303, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
      "{'loss': 1.6662, 'grad_norm': 0.3308461010456085, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
      "{'loss': 2.1632, 'grad_norm': 0.6644960045814514, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
      "{'loss': 1.738, 'grad_norm': 0.3049832284450531, 'learning_rate': 0.0002, 'epoch': 0.26}\n",
      "{'loss': 2.1273, 'grad_norm': 0.6054402589797974, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
      "{'loss': 1.7337, 'grad_norm': 0.30561283230781555, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
      "{'loss': 2.1182, 'grad_norm': 0.5388259887695312, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
      "{'loss': 1.7719, 'grad_norm': 0.4282227158546448, 'learning_rate': 0.0002, 'epoch': 0.27}\n",
      "{'loss': 2.1134, 'grad_norm': 0.576429545879364, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
      "{'loss': 1.6885, 'grad_norm': 0.3338683247566223, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
      "{'loss': 2.0621, 'grad_norm': 0.47880488634109497, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
      "{'loss': 1.8184, 'grad_norm': 0.31263625621795654, 'learning_rate': 0.0002, 'epoch': 0.28}\n",
      "{'loss': 2.09, 'grad_norm': 0.6022045016288757, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "{'loss': 1.8305, 'grad_norm': 0.35048410296440125, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "{'loss': 2.0801, 'grad_norm': 0.4556784927845001, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "{'loss': 1.8333, 'grad_norm': 0.33602654933929443, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "{'loss': 2.1686, 'grad_norm': 0.6041704416275024, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 1.757, 'grad_norm': 0.3004941940307617, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 2.0837, 'grad_norm': 0.5065962076187134, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 1.697, 'grad_norm': 0.3000433146953583, 'learning_rate': 0.0002, 'epoch': 0.3}\n",
      "{'loss': 2.1558, 'grad_norm': 0.6018896102905273, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 1.78, 'grad_norm': 0.3632386326789856, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 2.1224, 'grad_norm': 0.646503210067749, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 1.6647, 'grad_norm': 0.3155248463153839, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 2.0993, 'grad_norm': 0.594361424446106, 'learning_rate': 0.0002, 'epoch': 0.31}\n",
      "{'loss': 1.7568, 'grad_norm': 0.28640100359916687, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
      "{'loss': 2.0846, 'grad_norm': 0.5745497345924377, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
      "{'loss': 1.7651, 'grad_norm': 0.33033326268196106, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
      "{'loss': 2.0876, 'grad_norm': 0.45679470896720886, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
      "{'loss': 1.8259, 'grad_norm': 0.29952868819236755, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
      "{'loss': 2.0782, 'grad_norm': 0.5942296981811523, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
      "{'loss': 1.7932, 'grad_norm': 0.31033721566200256, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
      "{'loss': 2.0903, 'grad_norm': 0.507562518119812, 'learning_rate': 0.0002, 'epoch': 0.33}\n",
      "{'loss': 1.7048, 'grad_norm': 0.25829020142555237, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
      "{'loss': 2.1135, 'grad_norm': 0.6432790160179138, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
      "{'loss': 1.708, 'grad_norm': 0.29049259424209595, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
      "{'loss': 2.0103, 'grad_norm': 0.5252302289009094, 'learning_rate': 0.0002, 'epoch': 0.34}\n",
      "{'loss': 1.7893, 'grad_norm': 0.3750572204589844, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 2.0723, 'grad_norm': 0.5329424142837524, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 1.7689, 'grad_norm': 0.2799263894557953, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 2.0312, 'grad_norm': 0.6031118035316467, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 1.7769, 'grad_norm': 0.3012470602989197, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
      "{'loss': 2.0898, 'grad_norm': 0.6600245833396912, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
      "{'loss': 1.8153, 'grad_norm': 0.3846305012702942, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
      "{'loss': 2.0683, 'grad_norm': 0.4753846526145935, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
      "{'loss': 1.6976, 'grad_norm': 0.29961097240448, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 2.0979, 'grad_norm': 0.4485452473163605, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 1.7247, 'grad_norm': 0.25570473074913025, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 2.0651, 'grad_norm': 0.5323088765144348, 'learning_rate': 0.0002, 'epoch': 0.37}\n",
      "{'loss': 1.7239, 'grad_norm': 0.2553168535232544, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "{'loss': 2.059, 'grad_norm': 0.5582407712936401, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "{'loss': 1.8481, 'grad_norm': 0.4313000440597534, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "{'loss': 2.1797, 'grad_norm': 0.6662651300430298, 'learning_rate': 0.0002, 'epoch': 0.38}\n",
      "{'loss': 1.728, 'grad_norm': 0.3351733386516571, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
      "{'loss': 2.0507, 'grad_norm': 0.721682608127594, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
      "{'loss': 1.6208, 'grad_norm': 0.316204309463501, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
      "{'loss': 2.1748, 'grad_norm': nan, 'learning_rate': 0.0002, 'epoch': 0.39}\n",
      "{'loss': 1.7311, 'grad_norm': 0.34110045433044434, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 2.1072, 'grad_norm': 0.8178834319114685, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 1.8072, 'grad_norm': 0.29081034660339355, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 2.0454, 'grad_norm': 0.65265291929245, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 1.6786, 'grad_norm': 0.3848186135292053, 'learning_rate': 0.0002, 'epoch': 0.41}\n",
      "{'loss': 2.1382, 'grad_norm': 0.5864602327346802, 'learning_rate': 0.0002, 'epoch': 0.41}\n",
      "{'loss': 1.7338, 'grad_norm': 0.28509262204170227, 'learning_rate': 0.0002, 'epoch': 0.41}\n",
      "{'loss': 2.1005, 'grad_norm': 0.5522310137748718, 'learning_rate': 0.0002, 'epoch': 0.41}\n",
      "{'loss': 1.7337, 'grad_norm': 0.42434462904930115, 'learning_rate': 0.0002, 'epoch': 0.42}\n",
      "{'loss': 2.0919, 'grad_norm': 0.5748500823974609, 'learning_rate': 0.0002, 'epoch': 0.42}\n",
      "{'loss': 1.7364, 'grad_norm': 0.33011943101882935, 'learning_rate': 0.0002, 'epoch': 0.42}\n",
      "{'loss': 2.127, 'grad_norm': 0.6283487677574158, 'learning_rate': 0.0002, 'epoch': 0.42}\n",
      "{'loss': 1.7207, 'grad_norm': 0.30124691128730774, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "{'loss': 2.0338, 'grad_norm': 0.7760521769523621, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "{'loss': 1.7409, 'grad_norm': 0.2806946337223053, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "{'loss': 2.0289, 'grad_norm': 0.6321647763252258, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "{'loss': 1.8095, 'grad_norm': 0.3652421236038208, 'learning_rate': 0.0002, 'epoch': 0.44}\n",
      "{'loss': 2.0027, 'grad_norm': 0.7694418430328369, 'learning_rate': 0.0002, 'epoch': 0.44}\n",
      "{'loss': 1.7839, 'grad_norm': 0.328391969203949, 'learning_rate': 0.0002, 'epoch': 0.44}\n",
      "{'loss': 2.0645, 'grad_norm': 0.8462440371513367, 'learning_rate': 0.0002, 'epoch': 0.44}\n",
      "{'loss': 1.754, 'grad_norm': 0.32977572083473206, 'learning_rate': 0.0002, 'epoch': 0.45}\n",
      "{'loss': 2.1222, 'grad_norm': 0.6117797493934631, 'learning_rate': 0.0002, 'epoch': 0.45}\n",
      "{'loss': 1.74, 'grad_norm': 0.28201353549957275, 'learning_rate': 0.0002, 'epoch': 0.45}\n",
      "{'loss': 2.0479, 'grad_norm': 0.8903079032897949, 'learning_rate': 0.0002, 'epoch': 0.45}\n",
      "{'loss': 1.7688, 'grad_norm': 0.31003883481025696, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 2.034, 'grad_norm': 0.4886038601398468, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 1.7282, 'grad_norm': 0.30773332715034485, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 2.1452, 'grad_norm': 0.6512314677238464, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 1.7858, 'grad_norm': 0.31680893898010254, 'learning_rate': 0.0002, 'epoch': 0.46}\n",
      "{'loss': 2.078, 'grad_norm': 0.9991954565048218, 'learning_rate': 0.0002, 'epoch': 0.47}\n",
      "{'loss': 1.7455, 'grad_norm': 0.3124193847179413, 'learning_rate': 0.0002, 'epoch': 0.47}\n",
      "{'loss': 2.1019, 'grad_norm': 0.7681265473365784, 'learning_rate': 0.0002, 'epoch': 0.47}\n",
      "{'loss': 1.7349, 'grad_norm': 0.31002750992774963, 'learning_rate': 0.0002, 'epoch': 0.47}\n",
      "{'loss': 2.0781, 'grad_norm': 0.607957124710083, 'learning_rate': 0.0002, 'epoch': 0.48}\n",
      "{'loss': 1.7763, 'grad_norm': 0.4649103879928589, 'learning_rate': 0.0002, 'epoch': 0.48}\n",
      "{'loss': 2.0825, 'grad_norm': 0.6059979200363159, 'learning_rate': 0.0002, 'epoch': 0.48}\n",
      "{'loss': 1.7495, 'grad_norm': 0.302939772605896, 'learning_rate': 0.0002, 'epoch': 0.48}\n",
      "{'loss': 2.0503, 'grad_norm': 0.5127265453338623, 'learning_rate': 0.0002, 'epoch': 0.49}\n",
      "{'loss': 1.6578, 'grad_norm': 0.27259865403175354, 'learning_rate': 0.0002, 'epoch': 0.49}\n",
      "{'loss': 2.0625, 'grad_norm': 0.9448756575584412, 'learning_rate': 0.0002, 'epoch': 0.49}\n",
      "{'loss': 1.7379, 'grad_norm': 0.33092811703681946, 'learning_rate': 0.0002, 'epoch': 0.49}\n",
      "{'loss': 2.0805, 'grad_norm': 1.0118168592453003, 'learning_rate': 0.0002, 'epoch': 0.5}\n",
      "{'loss': 1.7776, 'grad_norm': 0.39322134852409363, 'learning_rate': 0.0002, 'epoch': 0.5}\n",
      "{'loss': 2.1119, 'grad_norm': 0.6539556980133057, 'learning_rate': 0.0002, 'epoch': 0.5}\n",
      "{'loss': 1.7508, 'grad_norm': 0.29814332723617554, 'learning_rate': 0.0002, 'epoch': 0.5}\n",
      "{'loss': 2.0209, 'grad_norm': 0.7264540195465088, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "{'loss': 1.74, 'grad_norm': 0.3128388524055481, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "{'loss': 2.1915, 'grad_norm': 0.8430888056755066, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "{'loss': 1.749, 'grad_norm': 0.280899316072464, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "{'loss': 2.0695, 'grad_norm': 0.6881390810012817, 'learning_rate': 0.0002, 'epoch': 0.52}\n",
      "{'loss': 1.7607, 'grad_norm': 0.3058167099952698, 'learning_rate': 0.0002, 'epoch': 0.52}\n",
      "{'loss': 2.1113, 'grad_norm': 0.5654197335243225, 'learning_rate': 0.0002, 'epoch': 0.52}\n",
      "{'loss': 1.7811, 'grad_norm': 0.3601042330265045, 'learning_rate': 0.0002, 'epoch': 0.52}\n",
      "{'loss': 2.1377, 'grad_norm': 1.3866455554962158, 'learning_rate': 0.0002, 'epoch': 0.53}\n",
      "{'loss': 1.7634, 'grad_norm': 0.35836929082870483, 'learning_rate': 0.0002, 'epoch': 0.53}\n",
      "{'loss': 2.0772, 'grad_norm': 0.6362247467041016, 'learning_rate': 0.0002, 'epoch': 0.53}\n",
      "{'loss': 1.7833, 'grad_norm': 0.298450767993927, 'learning_rate': 0.0002, 'epoch': 0.53}\n",
      "{'loss': 2.1273, 'grad_norm': 1.143080711364746, 'learning_rate': 0.0002, 'epoch': 0.54}\n",
      "{'loss': 1.7901, 'grad_norm': 0.49744898080825806, 'learning_rate': 0.0002, 'epoch': 0.54}\n",
      "{'loss': 2.0021, 'grad_norm': 0.626569926738739, 'learning_rate': 0.0002, 'epoch': 0.54}\n",
      "{'loss': 1.7489, 'grad_norm': 0.29968753457069397, 'learning_rate': 0.0002, 'epoch': 0.54}\n",
      "{'loss': 2.0649, 'grad_norm': 0.6319749355316162, 'learning_rate': 0.0002, 'epoch': 0.55}\n",
      "{'loss': 1.7488, 'grad_norm': 0.27107712626457214, 'learning_rate': 0.0002, 'epoch': 0.55}\n",
      "{'loss': 2.0697, 'grad_norm': 0.6071803569793701, 'learning_rate': 0.0002, 'epoch': 0.55}\n",
      "{'loss': 1.7413, 'grad_norm': 0.3963755667209625, 'learning_rate': 0.0002, 'epoch': 0.55}\n",
      "{'loss': 2.0962, 'grad_norm': 0.6870559453964233, 'learning_rate': 0.0002, 'epoch': 0.56}\n",
      "{'loss': 1.7486, 'grad_norm': 0.34439581632614136, 'learning_rate': 0.0002, 'epoch': 0.56}\n",
      "{'loss': 2.0616, 'grad_norm': 0.564185380935669, 'learning_rate': 0.0002, 'epoch': 0.56}\n",
      "{'loss': 1.7746, 'grad_norm': 0.4649791717529297, 'learning_rate': 0.0002, 'epoch': 0.56}\n",
      "{'loss': 2.0796, 'grad_norm': 0.6807855367660522, 'learning_rate': 0.0002, 'epoch': 0.57}\n",
      "{'loss': 1.8361, 'grad_norm': 0.6787763833999634, 'learning_rate': 0.0002, 'epoch': 0.57}\n",
      "{'loss': 2.1235, 'grad_norm': 0.8280042409896851, 'learning_rate': 0.0002, 'epoch': 0.57}\n",
      "{'loss': 1.7659, 'grad_norm': 0.30064132809638977, 'learning_rate': 0.0002, 'epoch': 0.57}\n",
      "{'loss': 2.0272, 'grad_norm': 0.8135947585105896, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "{'loss': 1.6861, 'grad_norm': 0.2925015091896057, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "{'loss': 2.0991, 'grad_norm': 0.7926996946334839, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "{'loss': 1.7387, 'grad_norm': 0.33067163825035095, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "{'loss': 2.0964, 'grad_norm': 0.5952850580215454, 'learning_rate': 0.0002, 'epoch': 0.59}\n",
      "{'loss': 1.7974, 'grad_norm': 0.39519214630126953, 'learning_rate': 0.0002, 'epoch': 0.59}\n",
      "{'loss': 2.0423, 'grad_norm': 1.09895920753479, 'learning_rate': 0.0002, 'epoch': 0.59}\n",
      "{'loss': 1.7138, 'grad_norm': 0.3837592601776123, 'learning_rate': 0.0002, 'epoch': 0.59}\n",
      "{'loss': 2.0831, 'grad_norm': 0.8535382747650146, 'learning_rate': 0.0002, 'epoch': 0.6}\n",
      "{'loss': 1.7297, 'grad_norm': 0.30615732073783875, 'learning_rate': 0.0002, 'epoch': 0.6}\n",
      "{'loss': 2.0867, 'grad_norm': 0.6730674505233765, 'learning_rate': 0.0002, 'epoch': 0.6}\n",
      "{'loss': 1.7237, 'grad_norm': 0.2582855522632599, 'learning_rate': 0.0002, 'epoch': 0.6}\n",
      "{'loss': 2.1095, 'grad_norm': 0.5829851627349854, 'learning_rate': 0.0002, 'epoch': 0.61}\n",
      "{'loss': 1.7465, 'grad_norm': 0.4884287118911743, 'learning_rate': 0.0002, 'epoch': 0.61}\n",
      "{'loss': 2.1478, 'grad_norm': 0.8634878993034363, 'learning_rate': 0.0002, 'epoch': 0.61}\n",
      "{'loss': 1.7475, 'grad_norm': 0.31616440415382385, 'learning_rate': 0.0002, 'epoch': 0.61}\n",
      "{'loss': 2.0504, 'grad_norm': 0.5961717367172241, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 1.7978, 'grad_norm': 0.5623438954353333, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 2.0446, 'grad_norm': 0.6098688840866089, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 1.7496, 'grad_norm': 0.46859702467918396, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 2.0831, 'grad_norm': 0.7029165625572205, 'learning_rate': 0.0002, 'epoch': 0.62}\n",
      "{'loss': 1.6388, 'grad_norm': 0.534348726272583, 'learning_rate': 0.0002, 'epoch': 0.63}\n",
      "{'loss': 2.1292, 'grad_norm': 0.641313374042511, 'learning_rate': 0.0002, 'epoch': 0.63}\n",
      "{'loss': 1.6214, 'grad_norm': 0.3664821684360504, 'learning_rate': 0.0002, 'epoch': 0.63}\n",
      "{'loss': 2.0572, 'grad_norm': 0.7635062336921692, 'learning_rate': 0.0002, 'epoch': 0.63}\n",
      "{'loss': 1.7173, 'grad_norm': 0.8571290373802185, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 2.0305, 'grad_norm': 0.776189386844635, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 1.742, 'grad_norm': 0.4696906507015228, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 2.1082, 'grad_norm': 0.6453405022621155, 'learning_rate': 0.0002, 'epoch': 0.64}\n",
      "{'loss': 1.7041, 'grad_norm': 0.2974637448787689, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "{'loss': 2.0702, 'grad_norm': 0.6899779438972473, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "{'loss': 1.6693, 'grad_norm': 0.35657456517219543, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "{'loss': 2.0519, 'grad_norm': 1.010432481765747, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "{'loss': 1.7206, 'grad_norm': 0.2943773865699768, 'learning_rate': 0.0002, 'epoch': 0.66}\n",
      "{'loss': 2.0321, 'grad_norm': 0.5573833584785461, 'learning_rate': 0.0002, 'epoch': 0.66}\n",
      "{'loss': 1.7527, 'grad_norm': 0.40246453881263733, 'learning_rate': 0.0002, 'epoch': 0.66}\n",
      "{'loss': 2.0708, 'grad_norm': 0.5974081158638, 'learning_rate': 0.0002, 'epoch': 0.66}\n",
      "{'loss': 1.761, 'grad_norm': 0.37245991826057434, 'learning_rate': 0.0002, 'epoch': 0.67}\n",
      "{'loss': 2.0961, 'grad_norm': 0.5170944929122925, 'learning_rate': 0.0002, 'epoch': 0.67}\n",
      "{'loss': 1.7894, 'grad_norm': 0.33560365438461304, 'learning_rate': 0.0002, 'epoch': 0.67}\n",
      "{'loss': 2.0681, 'grad_norm': 0.5920451879501343, 'learning_rate': 0.0002, 'epoch': 0.67}\n",
      "{'loss': 1.7485, 'grad_norm': 0.39324653148651123, 'learning_rate': 0.0002, 'epoch': 0.68}\n",
      "{'loss': 2.0405, 'grad_norm': 0.8591993451118469, 'learning_rate': 0.0002, 'epoch': 0.68}\n",
      "{'loss': 1.7323, 'grad_norm': 0.3672366142272949, 'learning_rate': 0.0002, 'epoch': 0.68}\n",
      "{'loss': 2.1353, 'grad_norm': nan, 'learning_rate': 0.0002, 'epoch': 0.68}\n",
      "{'loss': 1.7444, 'grad_norm': 0.29179647564888, 'learning_rate': 0.0002, 'epoch': 0.69}\n",
      "{'loss': 2.0657, 'grad_norm': 1.3186883926391602, 'learning_rate': 0.0002, 'epoch': 0.69}\n",
      "{'loss': 1.7488, 'grad_norm': 0.2908017933368683, 'learning_rate': 0.0002, 'epoch': 0.69}\n",
      "{'loss': 2.0617, 'grad_norm': 0.6074446439743042, 'learning_rate': 0.0002, 'epoch': 0.69}\n",
      "{'loss': 1.7185, 'grad_norm': 0.35575070977211, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
      "{'loss': 2.0985, 'grad_norm': 0.7929274439811707, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
      "{'loss': 1.6993, 'grad_norm': 0.3201938271522522, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
      "{'loss': 2.0871, 'grad_norm': 0.6099278926849365, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
      "{'loss': 1.7158, 'grad_norm': 0.47688645124435425, 'learning_rate': 0.0002, 'epoch': 0.71}\n",
      "{'loss': 2.1504, 'grad_norm': 0.8092754483222961, 'learning_rate': 0.0002, 'epoch': 0.71}\n",
      "{'loss': 1.7155, 'grad_norm': 0.39168548583984375, 'learning_rate': 0.0002, 'epoch': 0.71}\n",
      "{'loss': 2.0515, 'grad_norm': 0.6992008090019226, 'learning_rate': 0.0002, 'epoch': 0.71}\n",
      "{'loss': 1.7063, 'grad_norm': 0.2872866094112396, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "{'loss': 2.0902, 'grad_norm': 0.5493375062942505, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "{'loss': 1.7659, 'grad_norm': 0.283322811126709, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "{'loss': 2.0202, 'grad_norm': 0.7215416431427002, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "{'loss': 1.7771, 'grad_norm': 0.566802442073822, 'learning_rate': 0.0002, 'epoch': 0.73}\n",
      "{'loss': 2.0432, 'grad_norm': 0.5321813821792603, 'learning_rate': 0.0002, 'epoch': 0.73}\n",
      "{'loss': 1.6762, 'grad_norm': 0.3240100145339966, 'learning_rate': 0.0002, 'epoch': 0.73}\n",
      "{'loss': 2.1116, 'grad_norm': 0.9584453105926514, 'learning_rate': 0.0002, 'epoch': 0.73}\n",
      "{'loss': 1.8134, 'grad_norm': 0.41617587208747864, 'learning_rate': 0.0002, 'epoch': 0.74}\n",
      "{'loss': 2.0542, 'grad_norm': 1.3846657276153564, 'learning_rate': 0.0002, 'epoch': 0.74}\n",
      "{'loss': 1.799, 'grad_norm': 0.31945276260375977, 'learning_rate': 0.0002, 'epoch': 0.74}\n",
      "{'loss': 2.1066, 'grad_norm': 0.6979069709777832, 'learning_rate': 0.0002, 'epoch': 0.74}\n",
      "{'loss': 1.7142, 'grad_norm': 0.299528032541275, 'learning_rate': 0.0002, 'epoch': 0.75}\n",
      "{'loss': 2.0472, 'grad_norm': 0.799445629119873, 'learning_rate': 0.0002, 'epoch': 0.75}\n",
      "{'loss': 1.7081, 'grad_norm': 0.37038519978523254, 'learning_rate': 0.0002, 'epoch': 0.75}\n",
      "{'loss': 2.0529, 'grad_norm': 0.5954427123069763, 'learning_rate': 0.0002, 'epoch': 0.75}\n",
      "{'loss': 1.6913, 'grad_norm': 0.3167668581008911, 'learning_rate': 0.0002, 'epoch': 0.76}\n",
      "{'loss': 2.0116, 'grad_norm': 0.6364691257476807, 'learning_rate': 0.0002, 'epoch': 0.76}\n",
      "{'loss': 1.7259, 'grad_norm': 0.6700994372367859, 'learning_rate': 0.0002, 'epoch': 0.76}\n",
      "{'loss': 2.059, 'grad_norm': 0.5870603322982788, 'learning_rate': 0.0002, 'epoch': 0.76}\n",
      "{'loss': 1.7739, 'grad_norm': 0.3833858072757721, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 2.1244, 'grad_norm': 0.56512051820755, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 1.7003, 'grad_norm': 0.3195854127407074, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 2.0726, 'grad_norm': 0.8445408940315247, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 1.8136, 'grad_norm': 0.36517757177352905, 'learning_rate': 0.0002, 'epoch': 0.77}\n",
      "{'loss': 2.071, 'grad_norm': 0.49650126695632935, 'learning_rate': 0.0002, 'epoch': 0.78}\n",
      "{'loss': 1.7461, 'grad_norm': 0.2609909474849701, 'learning_rate': 0.0002, 'epoch': 0.78}\n",
      "{'loss': 2.0472, 'grad_norm': 0.9690979719161987, 'learning_rate': 0.0002, 'epoch': 0.78}\n",
      "{'loss': 1.7312, 'grad_norm': 0.32780101895332336, 'learning_rate': 0.0002, 'epoch': 0.78}\n",
      "{'loss': 2.0461, 'grad_norm': 0.543063759803772, 'learning_rate': 0.0002, 'epoch': 0.79}\n",
      "{'loss': 1.8082, 'grad_norm': 0.5759516954421997, 'learning_rate': 0.0002, 'epoch': 0.79}\n",
      "{'loss': 2.0908, 'grad_norm': 0.6738630533218384, 'learning_rate': 0.0002, 'epoch': 0.79}\n",
      "{'loss': 1.7166, 'grad_norm': 0.3401147127151489, 'learning_rate': 0.0002, 'epoch': 0.79}\n",
      "{'loss': 2.049, 'grad_norm': 0.813938319683075, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "{'loss': 1.6933, 'grad_norm': 0.33244600892066956, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "{'loss': 2.1122, 'grad_norm': 0.7939990758895874, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "{'loss': 1.6556, 'grad_norm': 0.4214877784252167, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "{'loss': 2.1116, 'grad_norm': 1.1338846683502197, 'learning_rate': 0.0002, 'epoch': 0.81}\n",
      "{'loss': 1.6332, 'grad_norm': 0.43532824516296387, 'learning_rate': 0.0002, 'epoch': 0.81}\n",
      "{'loss': 2.0228, 'grad_norm': 0.9551151394844055, 'learning_rate': 0.0002, 'epoch': 0.81}\n",
      "{'loss': 1.6659, 'grad_norm': 0.3219197988510132, 'learning_rate': 0.0002, 'epoch': 0.81}\n",
      "{'loss': 2.0141, 'grad_norm': 0.6917360424995422, 'learning_rate': 0.0002, 'epoch': 0.82}\n",
      "{'loss': 1.8396, 'grad_norm': 0.3950941264629364, 'learning_rate': 0.0002, 'epoch': 0.82}\n",
      "{'loss': 2.0341, 'grad_norm': 1.2758628129959106, 'learning_rate': 0.0002, 'epoch': 0.82}\n",
      "{'loss': 1.7345, 'grad_norm': 0.3537445664405823, 'learning_rate': 0.0002, 'epoch': 0.82}\n",
      "{'loss': 2.0651, 'grad_norm': 0.5886016488075256, 'learning_rate': 0.0002, 'epoch': 0.83}\n",
      "{'loss': 1.7843, 'grad_norm': 0.33395129442214966, 'learning_rate': 0.0002, 'epoch': 0.83}\n",
      "{'loss': 2.0145, 'grad_norm': 0.750821053981781, 'learning_rate': 0.0002, 'epoch': 0.83}\n",
      "{'loss': 1.7485, 'grad_norm': 0.31865358352661133, 'learning_rate': 0.0002, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: bd2a21df-0199-4317-881f-96b5bc64a68f)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0908, 'grad_norm': 0.5399209260940552, 'learning_rate': 0.0002, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b067f280>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: a4af9ad6-e647-4762-989e-954c3bb827da)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8396, 'grad_norm': 0.43165117502212524, 'learning_rate': 0.0002, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b072cbe0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 177d90b9-1556-46b8-a946-7646ebba483f)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1722, 'grad_norm': 0.9098647236824036, 'learning_rate': 0.0002, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b0795ed0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 3005075d-c08d-430f-a038-48213df999ba)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7056, 'grad_norm': 0.38092803955078125, 'learning_rate': 0.0002, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b057cd00>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 27f6b25e-73c2-49b9-befe-ec3b897f0ee2)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0151, 'grad_norm': 1.0573383569717407, 'learning_rate': 0.0002, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b067ece0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: c865a367-f103-46ea-a953-153be30cfe67)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7502, 'grad_norm': 0.3295097053050995, 'learning_rate': 0.0002, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b0736950>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 51940b6a-4cf1-453d-baf5-6ce43485dc87)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0772, 'grad_norm': 0.5600873827934265, 'learning_rate': 0.0002, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b0795f90>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 5fe51482-2bbf-4ad0-984f-61b93b50c2bb)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.722, 'grad_norm': 0.36509498953819275, 'learning_rate': 0.0002, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b072e740>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: a3fa7b5d-16e6-4bf4-a126-c2af3c2c6d01)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9207, 'grad_norm': 0.6150873899459839, 'learning_rate': 0.0002, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b067e410>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: 42dd5bc5-5650-46f1-b99d-3c29f1dc6c88)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7361, 'grad_norm': 0.8761472105979919, 'learning_rate': 0.0002, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b0736ce0>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: eb8b86a1-b319-4da1-ac6d-adac09f5da49)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9937, 'grad_norm': 0.6727592349052429, 'learning_rate': 0.0002, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b0797100>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: cc91cd6f-afdb-4a08-b61b-b769cd4ef83f)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7599, 'grad_norm': 0.321511834859848, 'learning_rate': 0.0002, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b072ef50>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: eac51428-83c7-43d8-b192-33bf75badfc2)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1096, 'grad_norm': 0.7874270081520081, 'learning_rate': 0.0002, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x76e2b067e950>: Failed to resolve \\'huggingface.co\\' ([Errno -3] Temporary failure in name resolution)\"))'), '(Request ID: dab2ee87-2303-4544-8e01-5a3b6b61766a)') - silently ignoring the lookup for the file config.json in TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "  warnings.warn(\n",
      "/home/bgsmagnuson/Documents/code_py/LLM-Debug-Assistant/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in TinyLlama/TinyLlama-1.1B-Chat-v1.0 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7635, 'grad_norm': 0.7014102339744568, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "{'loss': 2.1031, 'grad_norm': 0.8954417109489441, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "{'loss': 1.7226, 'grad_norm': 0.3867749869823456, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "{'loss': 2.0848, 'grad_norm': 0.9625787734985352, 'learning_rate': 0.0002, 'epoch': 0.88}\n",
      "{'loss': 1.7205, 'grad_norm': 0.4066599905490875, 'learning_rate': 0.0002, 'epoch': 0.88}\n",
      "{'loss': 2.018, 'grad_norm': 0.7131065130233765, 'learning_rate': 0.0002, 'epoch': 0.88}\n",
      "{'loss': 1.7381, 'grad_norm': 0.3091999292373657, 'learning_rate': 0.0002, 'epoch': 0.88}\n",
      "{'loss': 2.0922, 'grad_norm': 1.1560139656066895, 'learning_rate': 0.0002, 'epoch': 0.89}\n",
      "{'loss': 1.7891, 'grad_norm': 0.3340603709220886, 'learning_rate': 0.0002, 'epoch': 0.89}\n",
      "{'loss': 2.0563, 'grad_norm': 0.5417934656143188, 'learning_rate': 0.0002, 'epoch': 0.89}\n",
      "{'loss': 1.7593, 'grad_norm': 0.3191429376602173, 'learning_rate': 0.0002, 'epoch': 0.89}\n",
      "{'loss': 2.1422, 'grad_norm': 0.634017825126648, 'learning_rate': 0.0002, 'epoch': 0.9}\n",
      "{'loss': 1.6285, 'grad_norm': 0.28791019320487976, 'learning_rate': 0.0002, 'epoch': 0.9}\n",
      "{'loss': 2.0326, 'grad_norm': 0.6150171756744385, 'learning_rate': 0.0002, 'epoch': 0.9}\n",
      "{'loss': 1.7968, 'grad_norm': 0.4567704200744629, 'learning_rate': 0.0002, 'epoch': 0.9}\n",
      "{'loss': 2.0331, 'grad_norm': 0.6354982852935791, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
      "{'loss': 1.6879, 'grad_norm': 0.2720772325992584, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
      "{'loss': 2.0692, 'grad_norm': 0.6185084581375122, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
      "{'loss': 1.752, 'grad_norm': 0.37165331840515137, 'learning_rate': 0.0002, 'epoch': 0.91}\n",
      "{'loss': 2.0053, 'grad_norm': 0.6015257239341736, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 1.6843, 'grad_norm': 0.3314461410045624, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 2.0661, 'grad_norm': 1.170779824256897, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 1.7779, 'grad_norm': 0.35921719670295715, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 2.0423, 'grad_norm': 0.5969879627227783, 'learning_rate': 0.0002, 'epoch': 0.92}\n",
      "{'loss': 1.7217, 'grad_norm': 0.42612162232398987, 'learning_rate': 0.0002, 'epoch': 0.93}\n",
      "{'loss': 2.0747, 'grad_norm': 0.6306304931640625, 'learning_rate': 0.0002, 'epoch': 0.93}\n",
      "{'loss': 1.6598, 'grad_norm': 0.3179018497467041, 'learning_rate': 0.0002, 'epoch': 0.93}\n",
      "{'loss': 2.0783, 'grad_norm': 0.5858719944953918, 'learning_rate': 0.0002, 'epoch': 0.93}\n",
      "{'loss': 1.78, 'grad_norm': 0.5123910307884216, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      "{'loss': 2.0422, 'grad_norm': 0.6462236046791077, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      "{'loss': 1.6693, 'grad_norm': 0.34112536907196045, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      "{'loss': 2.0767, 'grad_norm': 0.5463022589683533, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      "{'loss': 1.6812, 'grad_norm': 0.36131954193115234, 'learning_rate': 0.0002, 'epoch': 0.95}\n",
      "{'loss': 2.0756, 'grad_norm': 0.5417917966842651, 'learning_rate': 0.0002, 'epoch': 0.95}\n",
      "{'loss': 1.6876, 'grad_norm': 0.32052743434906006, 'learning_rate': 0.0002, 'epoch': 0.95}\n",
      "{'loss': 2.0804, 'grad_norm': 0.5239958167076111, 'learning_rate': 0.0002, 'epoch': 0.95}\n",
      "{'loss': 1.7489, 'grad_norm': 0.4513303339481354, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "{'loss': 2.0257, 'grad_norm': 0.5562607645988464, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "{'loss': 1.8023, 'grad_norm': 0.3283414840698242, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "{'loss': 2.0413, 'grad_norm': 0.605828583240509, 'learning_rate': 0.0002, 'epoch': 0.96}\n",
      "{'loss': 1.824, 'grad_norm': 0.38630229234695435, 'learning_rate': 0.0002, 'epoch': 0.97}\n",
      "{'loss': 2.0659, 'grad_norm': 0.41121116280555725, 'learning_rate': 0.0002, 'epoch': 0.97}\n",
      "{'loss': 1.7449, 'grad_norm': 0.3072335720062256, 'learning_rate': 0.0002, 'epoch': 0.97}\n",
      "{'loss': 2.1026, 'grad_norm': 0.5582281947135925, 'learning_rate': 0.0002, 'epoch': 0.97}\n",
      "{'loss': 1.7424, 'grad_norm': 0.36148563027381897, 'learning_rate': 0.0002, 'epoch': 0.98}\n",
      "{'loss': 2.074, 'grad_norm': 0.6533815264701843, 'learning_rate': 0.0002, 'epoch': 0.98}\n",
      "{'loss': 1.7046, 'grad_norm': 0.31659698486328125, 'learning_rate': 0.0002, 'epoch': 0.98}\n",
      "{'loss': 2.0904, 'grad_norm': 0.48536211252212524, 'learning_rate': 0.0002, 'epoch': 0.98}\n",
      "{'loss': 1.6595, 'grad_norm': 0.34628674387931824, 'learning_rate': 0.0002, 'epoch': 0.99}\n",
      "{'loss': 2.0797, 'grad_norm': 0.7012848854064941, 'learning_rate': 0.0002, 'epoch': 0.99}\n",
      "{'loss': 1.7133, 'grad_norm': 0.30214473605155945, 'learning_rate': 0.0002, 'epoch': 0.99}\n",
      "{'loss': 1.9957, 'grad_norm': 0.49724331498146057, 'learning_rate': 0.0002, 'epoch': 0.99}\n",
      "{'loss': 1.6699, 'grad_norm': 0.3259538412094116, 'learning_rate': 0.0002, 'epoch': 1.0}\n",
      "{'loss': 1.9838, 'grad_norm': 0.5252965092658997, 'learning_rate': 0.0002, 'epoch': 1.0}\n",
      "{'train_runtime': 5405.933, 'train_samples_per_second': 7.519, 'train_steps_per_second': 1.88, 'train_loss': 1.9259297326427116, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62016cecf14416ab2deba0f455a241c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd84581c43664c4a95390646678d5843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1713400697.helios.16772.0:   0%|          | 0.00/91.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a74519fbeae4e4782cf67cfd20a9f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97597928188e4e608c85c4b9345c1ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1713400569.helios.16587.0:   0%|          | 0.00/5.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e045783e15f44799809b76f06214d080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/36.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/bgsmagnuson/results/commit/af3ab334a613607d0a63f574ff52a15b428f4b49', commit_message='tiny-llama-stack-overflow', commit_description='', oid='af3ab334a613607d0a63f574ff52a15b428f4b49', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"tiny-llama-stack-overflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
